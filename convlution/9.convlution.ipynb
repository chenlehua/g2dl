{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b2a1c1-64ac-4a5a-a9ba-a608be4b0391",
   "metadata": {},
   "source": [
    "# 卷积\n",
    "\n",
    "## 为什么需要卷积\n",
    "分类猫和狗，图片（12M像素），RGB图片和36M，使用100大小的单隐藏层MLP，模型有3.6B个原色，远多于世界上所有猫和狗的总数（900M狗，600M猫）\n",
    "## 平移不变形\n",
    "不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”\n",
    "## 局部性\n",
    "神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87bf53e-1647-4a69-9e79-04f3e106581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from g2fl import dl as dl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a818f6-9261-4c8a-be3a-b1982e49e3b7",
   "metadata": {},
   "source": [
    "![二维互相关运算。阴影部分是第一个输出元素，以及用于计算输出的输入张量元素和核张量元素：$0\\times0+1\\times1+3\\times2+4\\times3=19$.](../img/correlation.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3890b1-db54-47ad-a804-9cd8f9339418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):  #@save\n",
    "    \"\"\"计算二维互相关运算\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a9e9d08-1f2c-4570-8cd3-a9a0e3765c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee395b-77e1-4105-9308-9d6caf0af2c1",
   "metadata": {},
   "source": [
    "## 卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45cd1f41-f806-46a5-a557-e82e4b83a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3211ce-9e43-4079-987b-47aeda2b72e5",
   "metadata": {},
   "source": [
    "## 填充和步幅\n",
    "\n",
    "* 填充可以增加输出的高度和宽度。这常用来使输出与输入具有相同的高和宽。\n",
    "* 步幅可以减小输出的高和宽，例如输出的高和宽仅为输入的高和宽的$1/n$（$n$是一个大于$1$的整数）。\n",
    "* 填充和步幅可用于有效地调整数据的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0f9e9e9-bc47-45f0-a6b9-8d954ae89c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 为了方便起见，我们定义了一个计算卷积层的函数。\n",
    "# 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # 这里的（1，1）表示批量大小和通道数都是1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # 省略前两个维度：批量大小和通道\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "\n",
    "# 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1672a9-d4c7-4950-880a-2687517db769",
   "metadata": {},
   "source": [
    "填充不同的高度和宽度，使输出和输入具有相同的高度和宽度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4adf7d49-6bcc-4570-93f0-d06ea4253ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71746d-ba48-45c6-99ea-8e0939524d76",
   "metadata": {},
   "source": [
    "将高度和宽度的步幅设置为2，从而将输入的高度和宽度减半。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f5ee7ee-75f6-45fa-9101-407714eec55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631f1bc-5b98-4222-b179-98a1e1018ea8",
   "metadata": {},
   "source": [
    "## 多输入通道\n",
    "![两个输入通道的互相关计算。](../img/conv-multi-in.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3315335-b87a-4d68-b35f-dcf13ed691ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    # 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起\n",
    "    return sum(corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed54067b-17bb-4302-a75c-ad000b7060e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb5ae9-fe52-486a-b8f6-55923043f451",
   "metadata": {},
   "source": [
    "## 多输出通道\n",
    "每个通道看作对不同特征的响应。而现实可能更为复杂一些，因为每个通道不是独立学习的，而是为了共同使用而优化的。因此，多输出通道并不仅是学习多个单通道的检测器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b8896d-c473-4d2d-82ab-399e77de15fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。\n",
    "    # 最后将所有结果都叠加在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eda4e99b-136d-4c60-85e1-370fe59e131e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdebd10c-6f7f-4507-a846-77f698125db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a634d-4a43-4019-b041-42294d779c3a",
   "metadata": {},
   "source": [
    "## $1\\times 1$ 卷积层\n",
    "\n",
    "![互相关计算使用了具有3个输入通道和2个输出通道的 $1\\times 1$ 卷积核。其中，输入和输出具有相同的高度和宽度。](../img/conv-1x1.svg)\n",
    "\n",
    "* 当以每像素为基础应用时，$1\\times 1$卷积层相当于全连接层。\n",
    "* $1\\times 1$卷积层通常用于调整网络层的通道数量和控制模型复杂性。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a24c0-c16c-4201-bb4b-4cb686b26b09",
   "metadata": {},
   "source": [
    "# 池化层\n",
    "\n",
    "## 最大池化层和平均池化层\n",
    "\n",
    "\n",
    "![汇聚窗口形状为 $2\\times 2$ 的最大汇聚层。着色部分是第一个输出元素，以及用于计算这个输出的输入元素: $\\max(0, 1, 3, 4)=4$.](../img/pooling.svg)\n",
    "\n",
    "* 对于给定输入元素，最大池化层会输出该窗口内的最大值，平均池化层会输出该窗口内的平均值。\n",
    "* 池化层的主要优点之一是减轻卷积层对位置的过度敏感。\n",
    "* 我们可以指定池化层的填充和步幅。\n",
    "* 使用最大池化层以及大于1的步幅，可减少空间维度（如高度和宽度）。\n",
    "* 池化层的输出通道数与输入通道数相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e64c286-387e-4da7-bf45-780ceba8b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f210617f-da6c-4051-89d5-8581f0d20904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bc303b6-d7dd-4f91-b61e-21bee5818302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40ae77-aa21-4e8e-9b05-59a50e8135e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
