{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd7d0a52-619b-458b-b7a8-1fbd2893dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from g2fl import dl as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf741815-6feb-4720-8bb6-fb36ae7fb6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Go.\tVa !\n",
      "Hi.\tSalut !\n",
      "Run!\tCours !\n",
      "Run!\tCourez !\n",
      "Who?\tQui ?\n",
      "Wow!\tÇa alors !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dl.DATA_HUB['fra-eng'] = (dl.DATA_URL + 'fra-eng.zip',\n",
    "                          '94646ad1522d915e7b0f9296181140edcf86a4f5')\n",
    "\n",
    "\n",
    "def read_data_nmt():\n",
    "    \"\"\"载入“英语－法语”数据集\"\"\"\n",
    "    data_dir = dl.download_extract('fra-eng')\n",
    "    with open(os.path.join(data_dir, 'fra.txt'), 'r',\n",
    "              encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "raw_text = read_data_nmt()\n",
    "print(type(raw_text))\n",
    "print(raw_text[:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c62c54-7e78-4f98-bd8a-a3bc6eb0832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nmt(text):\n",
    "    \"\"\"预处理“英语－法语”数据集\"\"\"\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?') and prev_char != ' '\n",
    "\n",
    "    # 使用空格替换不间断空格\n",
    "    # 使用小写字母替换大写字母\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
    "    # 在单词和标点符号之间插入空格\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
    "           for i, char in enumerate(text)]\n",
    "    return ''.join(out)\n",
    "\n",
    "\n",
    "text = preprocess_nmt(raw_text)\n",
    "print(text[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1ae3f9-e9a2-4562-8793-db0f589c3a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_nmt(text, num_examples=None):\n",
    "    \"\"\"词元化“英语－法语”数据数据集\"\"\"\n",
    "    source, target = [], []\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i > num_examples:\n",
    "            break\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "    return source, target\n",
    "\n",
    "\n",
    "source, target = tokenize_nmt(text)\n",
    "source[:6], target[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05002ef4-c32a-41d7-a496-5b09a9aa7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist):\n",
    "    \"\"\"绘制列表长度对的直方图\"\"\"\n",
    "    dl.set_figsize()\n",
    "    _, _, patches = dl.plt.hist(\n",
    "        [[len(l) for l in xlist], [len(l) for l in ylist]])\n",
    "    dl.plt.xlabel(xlabel)\n",
    "    dl.plt.ylabel(ylabel)\n",
    "    for patch in patches[1].patches:\n",
    "        patch.set_hatch('/')\n",
    "    dl.plt.legend(legend)\n",
    "\n",
    "\n",
    "show_list_len_pair_hist(['source', 'target'], '# tokens per sequence',\n",
    "                        'count', source, target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e1de3-8919-41b6-813c-57d40b793fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = dl.Vocab(source, min_freq=2,\n",
    "                     reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "print(len(src_vocab))\n",
    "print(src_vocab.token_freqs[0:4])\n",
    "print(source[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24691f6e-1c77-4ac1-9628-d4f5e33a7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"截断或填充文本序列\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # 截断\n",
    "    return line + [padding_token] * (num_steps - len(line))  # 填充\n",
    "\n",
    "\n",
    "truncate_pad(src_vocab[source[0]], 10, src_vocab['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a9c2c-9c5c-4662-801f-6b0af7c1cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "b=a!=2\n",
    "c=b.type(torch.int32)\n",
    "print(c)\n",
    "c.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d56d13-66d3-4920-a84e-76ace52560a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_array_nmt(lines, vocab, num_steps):\n",
    "    \"\"\"将机器翻译的文本序列转换成小批量\"\"\"\n",
    "    lines = [vocab[l] for l in lines]\n",
    "    lines = [l + [vocab['<eos>']] for l in lines]\n",
    "    array = torch.tensor([truncate_pad(\n",
    "        l, num_steps, vocab['<pad>']) for l in lines])\n",
    "    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
    "    return array, valid_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c901cc36-77d5-4984-bb8d-50fd56a7a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
    "    \"\"\"返回翻译数据集的迭代器和词表\"\"\"\n",
    "    text = preprocess_nmt(read_data_nmt())\n",
    "    source, target = tokenize_nmt(text, num_examples)\n",
    "    src_vocab = dl.Vocab(source, min_freq=2,\n",
    "                         reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    tgt_vocab = dl.Vocab(target, min_freq=2,\n",
    "                         reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
    "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
    "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    data_iter = dl.load_array(data_arrays, batch_size)\n",
    "    return data_iter, src_vocab, tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282cbe08-6a25-4290-ab40-300101986c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size=2, num_steps=8)\n",
    "for X, X_valid_len, Y, Y_valid_len in train_iter:\n",
    "    print('X:', X.type(torch.int32))\n",
    "    print('X的有效长度:', X_valid_len)\n",
    "    print('Y:', Y.type(torch.int32))\n",
    "    print('Y的有效长度:', Y_valid_len)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db1c9a-aca0-4efa-ac49-c89fe5b882db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
